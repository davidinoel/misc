Securing User<->Server Interactions and Data Transmitted over TLS in General.

Assumption:
The entirety of the TLS crypto protocol and cipher suite being used to create, establish, and maintain the connection is secure, and the client and server are well-behaved, secure, and trusted as well.

Problem & Background:
For as long as a I can remember, vulnerabilities in TLS's ability to hide server and end-user interactions have been well documented relating to the fact that page sizes of public websites are known, or easily discoverable, and that using that knowledge and observing the traffic (size, timing, etc.), anyone on the line can fairly easily determine what a user is accessing on a particular website.

To broaden or abstract that, there are scenarious under which other encrypted traffic may be subject to such eavesdropping. Server<->server, server<->database, server to end-user applications, and on. If enough information about the applications, servers, databases, schemas, or whatever is being transmitted is known, while there *may* not be sufficient leakage to give observers knowledge of precisely what is being communicated, enough information may be leaked out to allow adversaries to gain a picture of what is going on behind the scenes. On the other hand, and in the absolute worst case, if users are allowed to fiddle knobs (inputs) and observe the traffic that results (the outputs), it *may* allow them to find weaknesses in, and eventually allow them to compromise the security of the crypto infrastructure entirely.

The best method of preventing this, and in general, the best method of ensuring the security of encrypted data sent between parties by an observer with either of these abilities is to allocate a constant bitrate between the server and client, to fill it with a constant stream of data (garbage/noise, when critical TX/RX is not required), and to inject the actual, or useful data into the stream in a seamless manner when needed.

While that can be a viable option in some situations, unfortunately, in many others it is quite impractical (large-scale web applications, for example), as you or the server you're connected to can't realistically allocate an entire N Kbps pipe to you and every other user connected to it. Nor would this necessarily be a desirable solution, as internet providers have recently begun to transition to capping data-usage, similar to cellular providers.

Solution ("Work-around"):
An alternative to allocating fixed pipes to users and filling them for as long as they are on the site, which may serve as a sort of middle-ground between the two is, assuming compression is not a concern (which at the time of initially writing this there were a few issues with compression in TLS), utilizing it, and randomly changing the ratio or level, as well as randomizing the interval between the changing of the ratio.
